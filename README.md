# llama-runner
Llama.cpp runner/swapper and proxy that emulates LMStudio / Ollama backends

Yes, this is mostly vibe-coded. Pull requests fixing glaring code issues / inefficiencies are welcome. Comments pointing out glaring code issues / inefficiencies are not welcome :>
